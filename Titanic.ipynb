{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8beab-5691-4f0a-ae52-d6ca6f651efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Classification\n",
    "# Make a system which tells whether the person will be save from sinking. \n",
    "# What factors were most likely lead to success-socio-economic status, age, gender and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5039b310-6e2b-421e-89a5-ee9e15cfb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cc3be5e-60b6-452b-bd51-43964a11b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "train_data = pd.read_csv(\"Downloads/train.csv\")\n",
    "test_data = pd.read_csv(\"Downloads/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac5a75dc-3f7e-43c6-bc85-ff0c07bf7411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# summary of data \n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c10f2ba1-4531-4fdd-8857-8ef58ceaef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# summary of data\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8c109a0-f6c7-47ac-bebf-0401caa81c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of train_data\n",
    "train_data_copy = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4fda935-a947-4a31-a4ad-10b51e6065b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for null values\n",
    "train_data_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6548141-3391-4fb6-ae88-2669c009d57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# satistical summary of data\n",
    "train_data_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "562c856a-636b-4f5f-ac6c-55ed7e1c0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values in embarked with the max value\n",
    "highest_embarked = train_data_copy['Embarked'].value_counts().idxmax()\n",
    "train_data_copy['Embarked'].fillna(highest_embarked, inplace=True)\n",
    "\n",
    "# Converting into numeric values\n",
    "train_data_copy['Embarked'] = train_data_copy['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6f54a35-c664-4704-b687-5a1d51429717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values in age with mean values\n",
    "groups = [['Pclass', 'Sex', 'Parch', 'SibSp'], ['Pclass', 'Sex', 'Parch'], ['Pclass', 'Sex']]\n",
    "for group in groups:\n",
    "    train_data_copy['Age'] = train_data_copy.groupby(group)['Age'].transform(lambda x: x.fillna(x.mean()))\n",
    "train_data_copy['Age'] = train_data_copy['Age'].fillna(train_data_copy['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "246e0d98-d5f1-4d3f-ab18-416fbd4785e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing value of cabin with U\n",
    "train_data_copy['Cabin'].fillna('U', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c5e0290-f34c-4c69-9fa6-bf5924ca4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting titles from name and replacing it with numeric values\n",
    "train_data_copy['Title'] = train_data_copy['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "train_data_copy['Title'] = train_data_copy['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "train_data_copy['Title'] = train_data_copy['Title'].replace(['Mlle', 'Ms'], 'Miss').replace('Mme', 'Mrs')\n",
    "train_data_copy['Title'] = train_data_copy['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ed7340d-c3e0-4991-9312-7aa0541b8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the family size by adding siblings,spouse and parentchild \n",
    "train_data_copy['FamilySize'] = train_data_copy['SibSp'] + train_data_copy['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fc02eae-0f98-43d8-8711-6a5954e8e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column alone for single persons\n",
    "train_data_copy['Alone'] = (train_data_copy['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# create a column child for children \n",
    "train_data_copy['Child'] = (train_data_copy['Age'] < 18).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b321dea1-a88c-4112-8505-1f3e5b7784cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 1st letter of cabin and converting it into numeri values\n",
    "train_data_copy['Cabin'] = train_data_copy['Cabin'].str[:1]\n",
    "cabin_mapping = {cabin: i for i, cabin in enumerate(set(train_data_copy['Cabin']))}\n",
    "train_data_copy['Cabin'] = train_data_copy['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0010efb8-dcee-4563-8790-8adb8bc06f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the survivor among passenger with same ticket number\n",
    "train_data_copy['TicketSurvivor'] = 0\n",
    "ticket_counts = train_data_copy['Ticket'].value_counts().to_dict()\n",
    "for ticket, count in ticket_counts.items():\n",
    "    if count > 1:\n",
    "        survivors = train_data_copy['Survived'][train_data_copy['Ticket'] == ticket].sum()\n",
    "        if survivors > 0:\n",
    "            train_data_copy.loc[train_data_copy['Ticket'] == ticket, 'TicketSurvivor'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fb1ffa2-6344-4e67-968c-2ca2bceef5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Child</th>\n",
       "      <th>TicketSurvivor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.184492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked  \\\n",
       "0         0       3    0  22.000000      1      0   7.2500      6         0   \n",
       "1         1       1    1  38.000000      1      0  71.2833      1         1   \n",
       "2         1       3    1  26.000000      0      0   7.9250      6         0   \n",
       "3         1       1    1  35.000000      1      0  53.1000      1         0   \n",
       "4         0       3    0  35.000000      0      0   8.0500      6         0   \n",
       "5         0       3    0  29.184492      0      0   8.4583      6         2   \n",
       "6         0       1    0  54.000000      0      0  51.8625      8         0   \n",
       "7         0       3    0   2.000000      3      1  21.0750      6         0   \n",
       "8         1       3    1  27.000000      0      2  11.1333      6         0   \n",
       "9         1       2    1  14.000000      1      0  30.0708      6         1   \n",
       "\n",
       "   Title  FamilySize  Alone  Child  TicketSurvivor  \n",
       "0      1           2      0      0               0  \n",
       "1      3           2      0      0               0  \n",
       "2      2           1      1      0               0  \n",
       "3      3           2      0      0               1  \n",
       "4      1           1      1      0               0  \n",
       "5      1           1      1      0               0  \n",
       "6      1           1      1      0               0  \n",
       "7      4           5      0      1               0  \n",
       "8      3           3      0      0               1  \n",
       "9      3           2      0      1               1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping unnesscary column \n",
    "train_data_copy = train_data_copy.drop(['Name', 'Ticket', 'PassengerId'], axis=1)\n",
    "\n",
    "# converting sex to numeric values\n",
    "train_data_copy['Sex'] = train_data_copy['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# print 1st few columns\n",
    "train_data_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1c41e4f-52d1-4168-baa3-f4c542fbaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coping data\n",
    "train_df = train_data_copy.copy()\n",
    "\n",
    "# setting target variable \n",
    "X = train_df.drop(['Survived'], axis = 1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "#standarizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = pd.DataFrame(sc.fit_transform(X.values), index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f4e5b3b-3716-42af-aea5-31e54d320647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eca46b1c-b55a-4892-841e-720973ee949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "Accuracy: 0.8156\n",
      "Precision: 0.8475\n",
      "Recall: 0.6757\n",
      "F1 Score: 0.7519\n",
      "ROC-AUC: 0.7950\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize the model\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {precision_svm:.4f}\")\n",
    "print(f\"Recall: {recall_svm:.4f}\")\n",
    "print(f\"F1 Score: {f1_svm:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "101b4003-87a6-4264-9649-f0d3cca518e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Accuracy: 0.8827\n",
      "Precision: 0.9077\n",
      "Recall: 0.7973\n",
      "F1 Score: 0.8489\n",
      "ROC-AUC: 0.8701\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the model\n",
    "gbc_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gbc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gbc = gbc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gbc = accuracy_score(y_test, y_pred_gbc)\n",
    "precision_gbc = precision_score(y_test, y_pred_gbc)\n",
    "recall_gbc = recall_score(y_test, y_pred_gbc)\n",
    "f1_gbc = f1_score(y_test, y_pred_gbc)\n",
    "roc_auc_gbc = roc_auc_score(y_test, y_pred_gbc)\n",
    "\n",
    "print(\"Gradient Boosting Classifier\")\n",
    "print(f\"Accuracy: {accuracy_gbc:.4f}\")\n",
    "print(f\"Precision: {precision_gbc:.4f}\")\n",
    "print(f\"Recall: {recall_gbc:.4f}\")\n",
    "print(f\"F1 Score: {f1_gbc:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_gbc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19f1b302-f445-4df7-94f3-fe7af99424ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "Accuracy: 0.8659\n",
      "Precision: 0.8788\n",
      "Recall: 0.7838\n",
      "F1 Score: 0.8286\n",
      "ROC-AUC: 0.8538\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
    "print(f\"Precision: {precision_knn:.4f}\")\n",
    "print(f\"Recall: {recall_knn:.4f}\")\n",
    "print(f\"F1 Score: {f1_knn:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84256ddd-8da1-4cb7-968d-dacb6dd785ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Accuracy: 0.8156\n",
      "Precision: 0.7595\n",
      "Recall: 0.8108\n",
      "F1 Score: 0.7843\n",
      "ROC-AUC: 0.8149\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
    "print(f\"Precision: {precision_dt:.4f}\")\n",
    "print(f\"Recall: {recall_dt:.4f}\")\n",
    "print(f\"F1 Score: {f1_dt:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d57fad3-06e2-4bfc-9fa0-2f941484f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.7654\n",
      "Precision: 0.7286\n",
      "Recall: 0.6892\n",
      "F1 Score: 0.7083\n",
      "ROC-AUC: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# Naive_bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
    "print(f\"Precision: {precision_nb:.4f}\")\n",
    "print(f\"Recall: {recall_nb:.4f}\")\n",
    "print(f\"F1 Score: {f1_nb:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_nb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a93eac82-4bff-4ccc-8d7b-325c466d346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshini\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Accuracy: 0.8436\n",
      "Precision: 0.8286\n",
      "Recall: 0.7838\n",
      "F1 Score: 0.8056\n",
      "ROC-AUC: 0.8347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize the model\n",
    "ab_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "ab_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ab = ab_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_ab = accuracy_score(y_test, y_pred_ab)\n",
    "precision_ab = precision_score(y_test, y_pred_ab)\n",
    "recall_ab = recall_score(y_test, y_pred_ab)\n",
    "f1_ab = f1_score(y_test, y_pred_ab)\n",
    "roc_auc_ab = roc_auc_score(y_test, y_pred_ab)\n",
    "\n",
    "print(\"AdaBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy_ab:.4f}\")\n",
    "print(f\"Precision: {precision_ab:.4f}\")\n",
    "print(f\"Recall: {recall_ab:.4f}\")\n",
    "print(f\"F1 Score: {f1_ab:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_ab:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf9f5218-dfd9-4d87-a5f7-704bab110b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Accuracy: 0.8380\n",
      "Precision: 0.8082\n",
      "Recall: 0.7973\n",
      "F1 Score: 0.8027\n",
      "ROC-AUC: 0.8320\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"Precision: {precision_xgb:.4f}\")\n",
    "print(f\"Recall: {recall_xgb:.4f}\")\n",
    "print(f\"F1 Score: {f1_xgb:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e305befc-9438-4d03-858e-deb42cd0fd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 268, number of negative: 444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 244\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376404 -> initscore=-0.504838\n",
      "[LightGBM] [Info] Start training from score -0.504838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Classifier\n",
      "Accuracy: 0.8715\n",
      "Precision: 0.8493\n",
      "Recall: 0.8378\n",
      "F1 Score: 0.8435\n",
      "ROC-AUC: 0.8665\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialize the model\n",
    "lgbm_model = LGBMClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "precision_lgbm = precision_score(y_test, y_pred_lgbm)\n",
    "recall_lgbm = recall_score(y_test, y_pred_lgbm)\n",
    "f1_lgbm = f1_score(y_test, y_pred_lgbm)\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(\"LightGBM Classifier\")\n",
    "print(f\"Accuracy: {accuracy_lgbm:.4f}\")\n",
    "print(f\"Precision: {precision_lgbm:.4f}\")\n",
    "print(f\"Recall: {recall_lgbm:.4f}\")\n",
    "print(f\"F1 Score: {f1_lgbm:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_lgbm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b41bd5cc-9419-4d31-9f5e-b97e233fffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier\n",
      "Accuracy: 0.8771\n",
      "Precision: 0.9062\n",
      "Recall: 0.7838\n",
      "F1 Score: 0.8406\n",
      "ROC-AUC: 0.8633\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize the model\n",
    "catboost_model = CatBoostClassifier(n_estimators=100, random_state=42, silent=True)\n",
    "\n",
    "# Train the model\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "precision_catboost = precision_score(y_test, y_pred_catboost)\n",
    "recall_catboost = recall_score(y_test, y_pred_catboost)\n",
    "f1_catboost = f1_score(y_test, y_pred_catboost)\n",
    "roc_auc_catboost = roc_auc_score(y_test, y_pred_catboost)\n",
    "\n",
    "print(\"CatBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy_catboost:.4f}\")\n",
    "print(f\"Precision: {precision_catboost:.4f}\")\n",
    "print(f\"Recall: {recall_catboost:.4f}\")\n",
    "print(f\"F1 Score: {f1_catboost:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_catboost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6f0e86a-2fcb-4a7f-bef7-5619e244ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8603\n",
      "Precision: 0.8451\n",
      "Recall: 0.8108\n",
      "F1 Score: 0.8276\n",
      "ROC-AUC: 0.8530\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7b38305-5e0b-42e0-a7db-9dba5de2a1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshini\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Roshini\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Voting Classifier Accuracy: 0.8770949720670391\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define models\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train individual models\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble with Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_model), \n",
    "    ('adaboost', adaboost_model), \n",
    "    ('gb', gb_model)\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate final prediction from the ensemble model\n",
    "ensemble_prediction = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy of the ensemble model\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_prediction)\n",
    "print(f\"Ensemble Voting Classifier Accuracy: {ensemble_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc5ed492-78f6-4bb0-9b80-ae99be1d7679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "Accuracy: 0.8827\n",
      "Precision: 0.8955\n",
      "Recall: 0.8108\n",
      "F1 Score: 0.8511\n",
      "ROC-AUC: 0.8721\n"
     ]
    }
   ],
   "source": [
    "# Voting classifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define individual classifiers\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "gbc_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize the Voting Classifier\n",
    "voting_model = VotingClassifier(estimators=[('rf', rf_model), ('logistic', logistic_model), ('svm', svm_model), ('gbc', gbc_model)], voting='soft')\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "precision_voting = precision_score(y_test, y_pred_voting)\n",
    "recall_voting = recall_score(y_test, y_pred_voting)\n",
    "f1_voting = f1_score(y_test, y_pred_voting)\n",
    "roc_auc_voting = roc_auc_score(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Classifier\")\n",
    "print(f\"Accuracy: {accuracy_voting:.4f}\")\n",
    "print(f\"Precision: {precision_voting:.4f}\")\n",
    "print(f\"Recall: {recall_voting:.4f}\")\n",
    "print(f\"F1 Score: {f1_voting:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_voting:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e0ca505-3d7b-4033-a13c-9ef617fc294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0              1         0\n",
      "1              2         1\n",
      "2              3         1\n",
      "3              4         1\n",
      "4              5         0\n",
      "..           ...       ...\n",
      "886          887         0\n",
      "887          888         1\n",
      "888          889         0\n",
      "889          890         0\n",
      "890          891         0\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "entire_dataset_predictions = voting_model.predict(X)\n",
    "\n",
    "# Creating a DataFrame with passenger IDs and predictions for the entire dataset\n",
    "passenger_ids_entire = train_data['PassengerId']\n",
    "predictions_entire_df = pd.DataFrame({'PassengerId': passenger_ids_entire, 'Survived': entire_dataset_predictions})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(predictions_entire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3eeff649-e1f3-494c-bafe-ffd3ff41c70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance to know which factor leads to success\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='viridis')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826806ed-039d-45c1-9cd7-186602fe9bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
